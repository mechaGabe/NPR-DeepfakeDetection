# Methodology Quick Reference - One Pager

## ðŸŽ¯ Core Methodology

**Research Question**: Do different generators leave artifacts at different scales?

**Approach**: Multi-Scale NPR with Attention Fusion
- Extract artifacts at 3 scales: 0.25Ã—, 0.5Ã—, 0.75Ã—
- Process each with separate ResNet branches
- Attention module learns adaptive weights
- Compare vs. single-scale baseline (0.5Ã—)

---

## ðŸ“Š Data at a Glance

| Aspect | Details |
|--------|---------|
| **Training** | ForenSynths: 40K images (ProGAN, 4 classes) |
| **Testing** | 50K+ images across 25+ generators (5 tables) |
| **Input** | 224Ã—224 RGB images |
| **Splits** | 80% train / 20% validation |

**Test Diversity**:
- Table 1: 8 GANs (ProGAN, StyleGAN, etc.)
- Table 2: 9 GANs (AttGAN, BEGAN, etc.)
- Table 3: 8 Diffusion (DDPM, LDM, SDv1/2)
- Table 4-5: Advanced (DALL-E, Midjourney, Glide)

---

## ðŸ—ï¸ Architecture Summary

**Baseline**: `Image â†’ NPR@0.5Ã— â†’ ResNet-50 â†’ Classifier` (11M params)

**Ours**:
```
Image â†’ [NPR@0.25Ã—, NPR@0.5Ã—, NPR@0.75Ã—]
          â†“         â†“         â†“
      ResNetâ‚   ResNetâ‚‚   ResNetâ‚ƒ
          â†“         â†“         â†“
        [128-dim features each]
                  â†“
          Attention Module
          (learns weights)
                  â†“
          Weighted Fusion
                  â†“
            Classifier
```
**Parameters**: 15M (+36% vs. baseline)

---

## âš™ï¸ Training Configuration

| Parameter | Value |
|-----------|-------|
| Optimizer | Adam (lr=0.0002) |
| Batch Size | 32 |
| Epochs | 50 |
| LR Decay | Ã—0.9 every 10 epochs |
| Loss | Binary Cross-Entropy |
| Hardware | RTX 3090 (24GB) |
| Training Time | 12.5 hours (multi-scale) |

---

## ðŸ§ª Experiments

1. **Baseline**: Single scale (0.5Ã—) - 8 hours
2. **Multi-Scale**: 3 scales (0.25Ã—, 0.5Ã—, 0.75Ã—) - 12 hours â­
3. **Ablation 1**: 2 scales coarse (0.25Ã—, 0.5Ã—) - 10 hours
4. **Ablation 2**: 2 scales fine (0.5Ã—, 0.75Ã—) - 10 hours
5. **Ablation 3**: 4 scales (0.2Ã—, 0.4Ã—, 0.6Ã—, 0.8Ã—) - 14 hours

**Total GPU Time**: 56 hours (~2.5 days)

---

## ðŸ“ˆ Evaluation Metrics

- **Accuracy**: % correct classifications
- **Average Precision (AP)**: Area under PR curve
- **Per-Generator**: Individual performance analysis
- **Attention Analysis**: Weight patterns per generator

**Success Criteria**: â‰¥2% improvement on â‰¥2 test tables

---

## ðŸ”¬ NPR Extraction Process

```python
For each scale s âˆˆ {0.25, 0.5, 0.75}:
  1. x_down = Downsample(image, scale=s, mode='nearest')
  2. x_recon = Upsample(x_down, scale=1/s, mode='nearest')
  3. NPR_s = image - x_recon  # Extract artifact
  4. features_s = ResNet_branch(NPR_s)  # 128-D
```

**Why Nearest-Neighbor?** Creates blocky artifacts different from GAN upsampling

---

## ðŸ“… Timeline

- **Week 1** (Nov 11-17): âœ… Implementation complete
- **Week 2-3** (Nov 18-Dec 1): Training + testing (56 GPU hours)
- **Week 4** (Dec 2-8): Analysis + visualization + report
- **Dec 9**: Final submission

---

## ðŸŽ¯ Expected Results

**Hypothesis**:
- **GANs**: Higher attention on coarse scales (0.25Ã—, 0.5Ã—)
  - Reason: Progressive upsampling
- **Diffusion**: Higher attention on fine scales (0.5Ã—, 0.75Ã—)
  - Reason: U-Net subtle artifacts

**Performance Target**: +2-5% accuracy improvement over baseline

---

## ðŸ’¾ Computational Resources

| Resource | Requirement | Available |
|----------|-------------|-----------|
| GPU | RTX 3090 (24GB) | âœ… Yes |
| Training Time | 56 hours | âœ… Feasible |
| Storage | 150GB | âœ… Sufficient |
| Memory | 11.2GB (batch=32) | âœ… Fits |

**Inference Speed**: 83 images/sec (real-time capable)

---

## ðŸ“Š Key Deliverables

1. **Models**: Baseline + Multi-scale + 3 ablations
2. **Results**: Performance tables (5 test sets Ã— 5 models)
3. **Visualizations**:
   - Attention heatmaps per generator
   - NPR artifact comparisons
   - Statistical distribution plots
4. **Analysis**: Which scales matter for which generators?
5. **Code**: Fully reproducible with documentation

---

## ðŸ”‘ Key Talking Points

1. **Innovation**: First work to explore multi-scale NPR with attention
2. **Efficiency**: Only +36% parameters for 3Ã— scale coverage
3. **Interpretability**: Attention weights reveal generator characteristics
4. **Generalization**: Test on 25+ unseen generators
5. **Practical**: Real-time inference (83 img/s)

---

## â“ Anticipated Questions & Answers

**Q: Why not just train 3 separate models?**
> Attention allows joint learning and cross-scale information sharing. More efficient than 3 independent models.

**Q: What if multi-scale doesn't help?**
> Still valuable! Negative results inform future work. Attention patterns still provide insights.

**Q: How did you choose scales 0.25, 0.5, 0.75?**
> 0.5Ã— is baseline. We test coarser (0.25Ã—) and finer (0.75Ã—). Ablations explore alternatives.

**Q: Computational cost too high?**
> Only 50% more training time than baseline. Inference is 83 img/sâ€”still real-time.

---

## ðŸŽ¨ Visual Elements Needed

For your slides, prepare:
- âœ… Architecture diagram (3 branches with attention)
- âœ… NPR extraction illustration
- âœ… Data distribution chart
- âœ… Timeline Gantt chart
- âœ… Expected attention heatmap (mock-up)
- âœ… Performance comparison bar chart

---

## ðŸ“ One-Sentence Summary

> **"We extend NPR deepfake detection by extracting upsampling artifacts at multiple scales and using an attention mechanism to adaptively weight which scales matter most for each generator type."**

---

**Use this for**: Quick reference during presentation prep, answering questions, or creating summary slides.
